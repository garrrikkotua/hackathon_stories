{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('stories_ImagesTexts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story_id</th>\n",
       "      <th>texts</th>\n",
       "      <th>images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127</td>\n",
       "      <td>['Нажмите «Изменить ПИН-код».', 'Введите новую...</td>\n",
       "      <td>['https://static2.tinkoff.ru/portfolio/stories...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>254</td>\n",
       "      <td>['Как\\xa0пополнить карту «Стрелка»', 'Введите ...</td>\n",
       "      <td>['https://static2.tinkoff.ru/portfolio/stories...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>865</td>\n",
       "      <td>['Как воспользоваться', 'Войдите в личный каби...</td>\n",
       "      <td>['https://static2.tinkoff.ru/portfolio/stories...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1491</td>\n",
       "      <td>['Музыка', 'Если вы вдруг заскучаете, попробуй...</td>\n",
       "      <td>['https://static2.tinkoff.ru/portfolio/stories...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>598</td>\n",
       "      <td>['Прыжки на батуте', 'Если бег, бассейн и трен...</td>\n",
       "      <td>['https://static2.tinkoff.ru/portfolio/stories...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   story_id                                              texts  \\\n",
       "0       127  ['Нажмите «Изменить ПИН-код».', 'Введите новую...   \n",
       "1       254  ['Как\\xa0пополнить карту «Стрелка»', 'Введите ...   \n",
       "2       865  ['Как воспользоваться', 'Войдите в личный каби...   \n",
       "3      1491  ['Музыка', 'Если вы вдруг заскучаете, попробуй...   \n",
       "4       598  ['Прыжки на батуте', 'Если бег, бассейн и трен...   \n",
       "\n",
       "                                              images  \n",
       "0  ['https://static2.tinkoff.ru/portfolio/stories...  \n",
       "1  ['https://static2.tinkoff.ru/portfolio/stories...  \n",
       "2  ['https://static2.tinkoff.ru/portfolio/stories...  \n",
       "3  ['https://static2.tinkoff.ru/portfolio/stories...  \n",
       "4  ['https://static2.tinkoff.ru/portfolio/stories...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from matplotlib import pyplot as plt\n",
    "import ast\n",
    "import urllib\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from torchvision import transforms\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pic(array, i, data):\n",
    "    array = ast.literal_eval(array)\n",
    "    for n, url in enumerate(array):\n",
    "        response = urllib.request.urlopen(url)\n",
    "        im = Image.open(BytesIO(response.read()))\n",
    "        directory = '/pictures/' + str(data['story_id'][i]) + '/'\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        im.save(directory + '{}.png'.format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to C:\\Users\\i1999/.cache\\torch\\checkpoints\\resnet18-5c106cde.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 44.7M/44.7M [00:08<00:00, 5.60MB/s]\n"
     ]
    }
   ],
   "source": [
    "net = resnet18(pretrained=True, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in net.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_converter(net, x):\n",
    "        net.eval()\n",
    "        x = net.conv1(x)\n",
    "        x = net.bn1(x)\n",
    "        x = net.relu(x)\n",
    "        x = net.maxpool(x)\n",
    "\n",
    "        x = net.layer1(x)\n",
    "        x = net.layer2(x)\n",
    "        x = net.layer3(x)\n",
    "        x = net.layer4(x)\n",
    "\n",
    "        x = net.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "folder = ImageFolder('C:/dev/hackathon-tinkoff/pictures/', transform=im_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2dd140e5c88>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(folder[3][0].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = folder._find_classes('C:/dev/hackathon-tinkoff/pictures/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:993: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    }
   ],
   "source": [
    "for i in folder:\n",
    "    if classes[0][i[1]] not in dic:\n",
    "        dic[classes[0][i[1]]].append(image_converter(net, i[0].unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "958"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dic.keys():\n",
    "    dic[key] = np.mean(dic[key], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic['501'] = np.mean(list(dic.values()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.bn0 = torch.nn.BatchNorm1d(512)\n",
    "        self.fc1 = torch.nn.Linear(512, 256)\n",
    "        self.ac1 = torch.nn.ELU()\n",
    "        self.bn1 = torch.nn.BatchNorm1d(256)\n",
    "        self.fc2 = torch.nn.Linear(256, 128)\n",
    "        self.ac2 = torch.nn.ELU()\n",
    "        self.bn2 = torch.nn.BatchNorm1d(128)\n",
    "        self.fc3 = torch.nn.Linear(128, 64)\n",
    "        self.ac3 = torch.nn.ELU()\n",
    "        self.bn3 = torch.nn.BatchNorm1d(64)\n",
    "        self.fc4 = torch.nn.Linear(64, 128)\n",
    "        self.ac4 = torch.nn.ELU()\n",
    "        self.bn4 = torch.nn.BatchNorm1d(128)\n",
    "        self.fc5 = torch.nn.Linear(128, 256)\n",
    "        self.ac5 = torch.nn.ELU()\n",
    "        self.bn5 = torch.nn.BatchNorm1d(256)\n",
    "        self.fc6 = torch.nn.Linear(256, 512)\n",
    "        \n",
    "    def forward(x):\n",
    "        x = self.bn0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.ac1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.ac2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.ac3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.ac4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.ac5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.ac6(x)\n",
    "        return x\n",
    "    \n",
    "    def encode(x):\n",
    "        x = self.bn0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.ac1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.ac2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.ac3(x)\n",
    "        x = self.bn3(x)\n",
    "        return x\n",
    "    \n",
    "    def decode(x):\n",
    "        x = self.fc4(x)\n",
    "        x = self.ac4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.ac5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.ac6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(dic.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X[:700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(dic, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
